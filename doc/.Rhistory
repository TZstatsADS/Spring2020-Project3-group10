if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
set.seed(0)
# set to the local path
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
train_dir <- "../data/train_set/"
train_image_dir <- paste(train_dir, "images/", sep="") #"../data/train_set/images/"
train_pt_dir <- paste(train_dir,  "points/", sep="") #"../data/train_set/points/"
train_label_path <- paste(train_dir, "label.csv", sep="") #"../data/train_set/label.csv"
run.cv <- FALSE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.feature.test <- F # process features for test set
run.test <- F # run evaluation on an independent test set
#train-test split
set.seed(0)
info <- read.csv(train_label_path) #"../data/train_set/label.csv"
#train-test split
set.seed(0)
info <- read.csv(train_label_path) #"../data/train_set/label.csv"
n <- nrow(info) #2500 imgaes
n_train <- round(n*(4/5), 0) #2000 images
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx) #500 images
## Slow! - Result stored
n_files <- length(list.files(train_image_dir)) #"../data/train_set/images/" -> 2500 total images
#
image_list <- list()
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
image_list[[1]]
#function to read fiducial points "../data/train_set/points/"
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix) #total 2500 files; total 78 fiducial points(x-y location) in a list
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
load("../output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
#save(dat_train, file="../output/feature_train.RData")
#save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
run.feature.test<-T
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
load("../output/feature_test.Rdata")
load("C:/Users/59446/Documents/GitHub/ADS_Teaching/Projects_StarterCodes/Project3-FacialEmotionRecognition/output/feature_test.RData")
View(dat_train)
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
load("../output/feature_test.Rdata")
baseline <- gbm(emotion_idx~. ,data =dat_train ,distribution = "multinomial", n.trees = 100,shrinkage = 0.02, n.minobsinnode = 15)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
labels = apply(baseline$fit, 1, which.max)
label<-factor(labels)
confusionMatrix(label, dat$emotion_idx)
labels = apply(base_line$fit, 1, which.max)
label<-factor(labels)
confusionMatrix(label, dat_train$emotion_idx)
load("C:/Users/59446/Documents/GitHub/Spring2020-Project3-group10/output/feature_test.RData")
View(dat_test)
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
set.seed(0)
# set to the local path
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
train_dir <- "../data/train_set/"
train_image_dir <- paste(train_dir, "images/", sep="") #"../data/train_set/images/"
train_pt_dir <- paste(train_dir,  "points/", sep="") #"../data/train_set/points/"
train_label_path <- paste(train_dir, "label.csv", sep="") #"../data/train_set/label.csv"
run.cv <- FALSE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.feature.test <- F # process features for test set
run.test <- F # run evaluation on an independent test set
#train-test split
set.seed(0)
info <- read.csv(train_label_path) #"../data/train_set/label.csv"
n <- nrow(info) #2500 imgaes
n_train <- round(n*(4/5), 0) #2000 images
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx) #500 images
## Slow! - Result stored
n_files <- length(list.files(train_image_dir)) #"../data/train_set/images/" -> 2500 total images
#
image_list <- list()
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
image_list[[1]]
#function to read fiducial points "../data/train_set/points/"
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix) #total 2500 files; total 78 fiducial points(x-y location) in a list
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
load("../output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
load("../output/feature_test.Rdata")
View(dat_test)
load("C:/Users/59446/Desktop/baseline.RData")
View(dat_test)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
View(fiducial_pt_list)
View(baseline)
baseline.confusion.mat
View(baseline.confusion.mat)
View(baseline)
View(baseline)
pred.result.factor <- as.factor(as.numeric(apply(baseline$fit, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
pred.result.factor <- as.factor(as.numeric(apply(baseline$fit, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_train$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
labels = apply(baseline$fit, 1, which.max)
label<-factor(labels)
confusionMatrix(label, dat_train$emotion_idx)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_train,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_train,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_train$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
a<-dat_train$emotion_idx
baseline.confusion.mat = confusionMatrix(pred.result.factor,dat_train$emotion_idx)
baseline.confusion.mat$overall["Accuracy"]
labels = apply(baseline$fit, 1, which.max)
label<-factor(labels)
label[1:10]
labels[1:10]
pred.result.factor[1:10]
a<-baseline$fit
a[1,:]
a[1,]
baseline.pred <- predict.gbm(object = baseline_2,
newdata = dat_test,
n.trees = 100,
type = "response")
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
View(dat_train)
View(baseline)
baseline <- gbm(emotion_idx~. ,data =dat_train ,distribution = "multinomial", n.trees = 100,shrinkage = 0.02, n.minobsinnode = 15, cv.folds = 5)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_train,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_train$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
load("C:/Users/59446/Documents/GitHub/Spring2020-Project3-group10/output/feature_test.RData")
View(dat_test)
load("C:/Users/59446/Documents/GitHub/ADS_Teaching/Projects_StarterCodes/Project3-FacialEmotionRecognition/output/feature_test.RData")
View(dat_test)
