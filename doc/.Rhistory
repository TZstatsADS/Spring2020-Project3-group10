if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
set.seed(0)
# set to the local path
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
train_dir <- "../data/train_set/"
train_image_dir <- paste(train_dir, "images/", sep="") #"../data/train_set/images/"
train_pt_dir <- paste(train_dir,  "points/", sep="") #"../data/train_set/points/"
train_label_path <- paste(train_dir, "label.csv", sep="") #"../data/train_set/label.csv"
run.cv <- FALSE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.feature.test <- F # process features for test set
run.test <- F # run evaluation on an independent test set
#train-test split
set.seed(0)
info <- read.csv(train_label_path) #"../data/train_set/label.csv"
#train-test split
set.seed(0)
info <- read.csv(train_label_path) #"../data/train_set/label.csv"
n <- nrow(info) #2500 imgaes
n_train <- round(n*(4/5), 0) #2000 images
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx) #500 images
## Slow! - Result stored
n_files <- length(list.files(train_image_dir)) #"../data/train_set/images/" -> 2500 total images
#
image_list <- list()
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
image_list[[1]]
#function to read fiducial points "../data/train_set/points/"
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix) #total 2500 files; total 78 fiducial points(x-y location) in a list
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
load("../output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
#save(dat_train, file="../output/feature_train.RData")
#save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
run.feature.test<-T
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
load("../output/feature_test.Rdata")
load("C:/Users/59446/Documents/GitHub/ADS_Teaching/Projects_StarterCodes/Project3-FacialEmotionRecognition/output/feature_test.RData")
View(dat_train)
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
load("../output/feature_test.Rdata")
baseline <- gbm(emotion_idx~. ,data =dat_train ,distribution = "multinomial", n.trees = 100,shrinkage = 0.02, n.minobsinnode = 15)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
labels = apply(baseline$fit, 1, which.max)
label<-factor(labels)
confusionMatrix(label, dat$emotion_idx)
labels = apply(base_line$fit, 1, which.max)
label<-factor(labels)
confusionMatrix(label, dat_train$emotion_idx)
load("C:/Users/59446/Documents/GitHub/Spring2020-Project3-group10/output/feature_test.RData")
View(dat_test)
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
set.seed(0)
# set to the local path
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
train_dir <- "../data/train_set/"
train_image_dir <- paste(train_dir, "images/", sep="") #"../data/train_set/images/"
train_pt_dir <- paste(train_dir,  "points/", sep="") #"../data/train_set/points/"
train_label_path <- paste(train_dir, "label.csv", sep="") #"../data/train_set/label.csv"
run.cv <- FALSE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.feature.test <- F # process features for test set
run.test <- F # run evaluation on an independent test set
#train-test split
set.seed(0)
info <- read.csv(train_label_path) #"../data/train_set/label.csv"
n <- nrow(info) #2500 imgaes
n_train <- round(n*(4/5), 0) #2000 images
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx) #500 images
## Slow! - Result stored
n_files <- length(list.files(train_image_dir)) #"../data/train_set/images/" -> 2500 total images
#
image_list <- list()
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
image_list[[1]]
#function to read fiducial points "../data/train_set/points/"
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix) #total 2500 files; total 78 fiducial points(x-y location) in a list
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
load("../output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA # need add time of construction later
tm_feature_test <- NA
#
if(run.feature.train){
dat_train <- feature(fiducial_pt_list, train_idx)
# total 2500 imgaes: str(fiducial_pt_list) = list of 2500
#output n(train_idx)=2000 rows, each with 6007 variables: 6006 distances(horizontal+vertical)+emotion_index
}
if(run.feature.test){
dat_test <- feature(fiducial_pt_list, test_idx)
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
load("../output/feature_train.Rdata")
load("../output/feature_test.Rdata")
View(dat_test)
load("C:/Users/59446/Desktop/baseline.RData")
View(dat_test)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
View(fiducial_pt_list)
View(baseline)
baseline.confusion.mat
View(baseline.confusion.mat)
View(baseline)
View(baseline)
pred.result.factor <- as.factor(as.numeric(apply(baseline$fit, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
pred.result.factor <- as.factor(as.numeric(apply(baseline$fit, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_train$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
labels = apply(baseline$fit, 1, which.max)
label<-factor(labels)
confusionMatrix(label, dat_train$emotion_idx)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_train,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_train,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_train$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
a<-dat_train$emotion_idx
baseline.confusion.mat = confusionMatrix(pred.result.factor,dat_train$emotion_idx)
baseline.confusion.mat$overall["Accuracy"]
labels = apply(baseline$fit, 1, which.max)
label<-factor(labels)
label[1:10]
labels[1:10]
pred.result.factor[1:10]
a<-baseline$fit
a[1,:]
a[1,]
baseline.pred <- predict.gbm(object = baseline_2,
newdata = dat_test,
n.trees = 100,
type = "response")
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
View(dat_train)
View(baseline)
baseline <- gbm(emotion_idx~. ,data =dat_train ,distribution = "multinomial", n.trees = 100,shrinkage = 0.02, n.minobsinnode = 15, cv.folds = 5)
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_test,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_test$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
baseline.pred <- predict.gbm(object = baseline,
newdata = dat_train,
n.trees = 100,
type = "response")
#prediction result
pred.result.factor <- as.factor(as.numeric(apply(baseline.pred, 1, which.max)))
baseline.confusion.mat = confusionMatrix(dat_train$emotion_idx,pred.result.factor)
# error rate
baseline.confusion.mat$overall["Accuracy"]
load("C:/Users/59446/Documents/GitHub/Spring2020-Project3-group10/output/feature_test.RData")
View(dat_test)
load("C:/Users/59446/Documents/GitHub/ADS_Teaching/Projects_StarterCodes/Project3-FacialEmotionRecognition/output/feature_test.RData")
View(dat_test)
install.packages("mlbench")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
if(!require("gbm")){
install.packages("gbm")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(gbm)
set.seed(0)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# here replace it with your own path or manually set it in RStudio to where this rmd file is located.
# use relative path for reproducibility
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
t = c(50,100,150,200,250)
model_labels = paste("Number of trees in GBM function:", t)
#train-test split
info <- read.csv(train_label_path)
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx)
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
n_files <- length(list.files(train_image_dir))
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
#inner points
#for (i in 1:2500){
#  fiducial_pt_list[[i]] = fiducial_pt_list[[i]][c(19,21,23, #27,29,31,2,4,6,8,11,13,15,17,1,10,41,42,44,46,47,50,51,38,53,54,55,57,59,62,67,71,75),]
#}
# half points
for (i in 1:2500){
fiducial_pt_list[[i]] = fiducial_pt_list[[i]][c(19,21,23, 2,4,6,8,1,41,42,44,50,51,52,56,57,59,62,67,71,35,37,38),]
}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
}
save(dat_train, file="../output/feature_train.RData")
save(dat_test, file="../output/feature_test.RData")
library(h2o)
h2o.init()
y<-'emotion_idx'
nfolds <- 5
train<-as.h2o(dat_train)
test<-as.h2o(dat_test)
my_gbm <- h2o.gbm(y = y,
training_frame = train,
distribution = "multinomial",
ntrees = 50,
max_depth = 3,
min_rows = 2,
learn_rate = 0.1,
nfolds = nfolds,
fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE,
seed = 1)
h2o.confusionMatrix(my_gbm, newdata = test)
my_dl<-h2o.deeplearning(y=y,
training_frame = train,
distribution = "multinomial",
hidden = c(200,200),
nfolds = nfolds,
fold_assignment = "Modulo",
seed = 1,keep_cross_validation_predictions = TRUE)
h2o.confusionMatrix(my_dl, newdata = test)
ensemble <- h2o.stackedEnsemble(y = y,
training_frame = train,
model_id = "my_ensemble",
base_models = list(my_gbm, my_dl))
h2o.confusionMatrix(ensemble, newdata = test)
